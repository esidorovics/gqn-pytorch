{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GQN With Pool Representation and 8 Generative Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gqn import GenerativeQueryNetwork, partition\n",
    "from dataset import GQN_Dataset\n",
    "from torch.distributions import Normal\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"main.log\")\n",
    "print(\"Total steps: {}\".format(df[\"step\"].tolist()[-1]))\n",
    "models = glob.glob(\"checkpoints/checkpoint_model_*.pth\")\n",
    "models.sort(key=lambda x: os.path.getmtime(x))\n",
    "print(\"Last model checkpoint: {}\".format(models[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"step\"]>200000]\n",
    "# df = df[df[\"step\"]>0]\n",
    "step = df[\"step\"].to_list()\n",
    "ll = df[\"ll\"].to_list()\n",
    "kl = df[\"kl\"].to_list()\n",
    "elbo = df['elbo'].to_list()\n",
    "sigma = df['sigma'].to_list()\n",
    "mu = df['mu'].to_list()\n",
    "kl_av = []\n",
    "ll_av = []\n",
    "elbo_av = []\n",
    "\n",
    "average_step = 1000\n",
    "for i in range(average_step, len(step)):\n",
    "    kl_av.append(sum(kl[i-average_step:i])/average_step)\n",
    "    ll_av.append(sum(ll[i-average_step:i])/average_step)\n",
    "    elbo_av.append(sum(elbo[i-average_step:i])/average_step)\n",
    "step = step[average_step:]\n",
    "sigma = sigma[average_step:]\n",
    "mu =mu[average_step:]\n",
    "\n",
    "plt.figure(num=None, figsize=(18, 12))\n",
    "plt.subplot(231)\n",
    "plt.plot(step, elbo_av)\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.plot(step, ll_av)\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.plot(step, kl_av)\n",
    "plt.subplot(234)\n",
    "plt.plot(step, mu)\n",
    "plt.subplot(235)\n",
    "plt.plot(step, sigma)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_dataset = GQN_Dataset(root_dir=\"data/rooms-ring-camera/\", train=False)\n",
    "x, v = valid_dataset[1]\n",
    "x = x.view((1, *x.shape))\n",
    "v = v.view((1, *v.shape))\n",
    "\n",
    "max_m=5\n",
    "x, v, x_q, v_q = partition(x, v, max_m, 5)\n",
    "batch, *_ = x.shape\n",
    "print(x.shape)\n",
    "print(v.shape)\n",
    "print(x_q.shape)\n",
    "device = torch.device(\"cpu\")\n",
    "model = GenerativeQueryNetwork(x_dim=3, v_dim=7, r_dim=256, h_dim=128, z_dim=64, L=8, pool=True).to(device)\n",
    "model.eval()\n",
    "checkpoint = torch.load(models[-1])\n",
    "#checkpoint = torch.load(\"./checkpoints/checkpoint_model_240000.pth\") #\n",
    "# checkpoint = torch.load(\"./chkpnts/checkpoint_model_500000.pth\") #\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "x_mu = model.sample(x, v, v_q)\n",
    "# x_mu, r, kl = model(x, v, x_q, v_q)\n",
    "x_mu = x_mu.detach().cpu().numpy()\n",
    "x_context = x.numpy()\n",
    "x_query = x_q.numpy()\n",
    "\n",
    "x_context = np.moveaxis(x_context, [2, 3, 4], [-1, 2, 3])\n",
    "x_query = np.moveaxis(x_query, [1, 2, 3], [-1, -3, -2])\n",
    "x_mu = np.moveaxis(x_mu, [1, 2, 3], [-1, -3, -2])\n",
    "\n",
    "n = 36\n",
    "for i in range(n):\n",
    "    full = np.concatenate(x_context[i], axis=1)\n",
    "    space = np.ones(shape=(full.shape[0], 10, 3))\n",
    "    full = np.concatenate([full, space, x_mu[i], space, x_query[i]], axis=1)\n",
    "    plt.figure(num=None, figsize=(18, 6))\n",
    "    print(i)\n",
    "    plt.imshow(full)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9\n",
    "#i = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delta = 0.1\n",
    "new_images = 7\n",
    "change_n = 256\n",
    "#change_n = 3\n",
    "batch = 1\n",
    "\n",
    "_, _, x_dims, h, w = x.shape\n",
    "\n",
    "r = model.get_r(x, v)[i]\n",
    "r = r.cpu().detach().numpy()\n",
    "r_dims = r.shape\n",
    "print(r.shape)\n",
    "\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = torch.tensor(view_q)\n",
    "\n",
    "deltas = [delta * (j - new_images//2) for j in range(new_images)]\n",
    "for neuron_i in range(change_n):\n",
    "    delta_set = []\n",
    "    images = []\n",
    "    for cur_delta in deltas:\n",
    "        new_r = np.copy(r)\n",
    "        new_r.astype(np.float16)\n",
    "        new_r[neuron_i, 0, 0] += cur_delta\n",
    "        delta_set.append(\"{:.5}\".format(new_r[neuron_i, 0, 0]))\n",
    "        new_r = np.expand_dims(new_r, axis=0)\n",
    "        new_r = torch.tensor(new_r)\n",
    "\n",
    "        device = torch.device(\"cpu\")\n",
    "        new_r, view_q = new_r.to(device), view_q.to(device)\n",
    "        torch.manual_seed(8)\n",
    "        x_mu = model.sample_from_r((h, w), new_r, view_q)\n",
    "        x_mu = x_mu.detach().cpu().numpy()\n",
    "        images.append(x_mu)\n",
    "\n",
    "    images = np.array(images)\n",
    "    images = np.reshape(images, (new_images, x_dims, h, w))\n",
    "    images = np.moveaxis(images, [1, 2, 3], [-1, -3, -2])\n",
    "    images = np.concatenate(images, axis=1)\n",
    "    print(\"i: {}\".format(neuron_i+1))\n",
    "    print(\"      \",\"        \".join(delta_set))\n",
    "    plt.figure(num=None, figsize=(21,6))\n",
    "    plt.imshow(images)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=9\n",
    "delta = 0.1\n",
    "new_images = 7\n",
    "change_n = 256\n",
    "#change_n = 3\n",
    "batch = 1\n",
    "\n",
    "_, _, x_dims, h, w = x.shape\n",
    "\n",
    "r = model.get_r(x, v)[i]\n",
    "r = r.cpu().detach().numpy()\n",
    "r_dims = r.shape\n",
    "print(r.shape)\n",
    "\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = torch.tensor(view_q)\n",
    "\n",
    "deltas = [delta * (j - new_images//2) for j in range(new_images)]\n",
    "for neuron_i in range(change_n):\n",
    "    delta_set = []\n",
    "    images = []\n",
    "    for cur_delta in deltas:\n",
    "        new_r = np.copy(r)\n",
    "        new_r.astype(np.float16)\n",
    "        new_r[neuron_i, 0, 0] += cur_delta\n",
    "        delta_set.append(\"{:.5}\".format(new_r[neuron_i, 0, 0]))\n",
    "        new_r = np.expand_dims(new_r, axis=0)\n",
    "        new_r = torch.tensor(new_r)\n",
    "\n",
    "        device = torch.device(\"cpu\")\n",
    "        new_r, view_q = new_r.to(device), view_q.to(device)\n",
    "        torch.manual_seed(1)\n",
    "        x_mu = model.sample_from_r((h, w), new_r, view_q)\n",
    "        x_mu = x_mu.detach().cpu().numpy()\n",
    "        images.append(x_mu)\n",
    "\n",
    "    images = np.array(images)\n",
    "    images = np.reshape(images, (new_images, x_dims, h, w))\n",
    "    images = np.moveaxis(images, [1, 2, 3], [-1, -3, -2])\n",
    "    images = np.concatenate(images, axis=1)\n",
    "    print(\"i: {}\".format(neuron_i+1))\n",
    "    print(\"      \",\"        \".join(delta_set))\n",
    "    plt.figure(num=None, figsize=(21,6))\n",
    "    plt.imshow(images)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
