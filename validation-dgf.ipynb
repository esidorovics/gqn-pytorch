{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GQN With DGF - Pool Representation and 8 Generative Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gqn import GenerativeQueryNetwork, partition\n",
    "from dataset import GQN_Dataset\n",
    "from torch.distributions import Normal\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"main.log\")\n",
    "print(\"Total steps: {}\".format(df[\"step\"].tolist()[-1]))\n",
    "models = glob.glob(\"checkpoints/checkpoint_model_*.pth\")\n",
    "models.sort(key=lambda x: os.path.getmtime(x))\n",
    "print(\"Last model checkpoint: {}\".format(models[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"step\"]>200000]\n",
    "step = df[\"step\"].to_list()\n",
    "ll = df[\"ll\"].to_list()\n",
    "kl = df[\"kl\"].to_list()\n",
    "elbo = df['elbo'].to_list()\n",
    "sigma = df['sigma'].to_list()\n",
    "mu = df['mu'].to_list()\n",
    "kl_av = []\n",
    "ll_av = []\n",
    "elbo_av = []\n",
    "\n",
    "average_step = 100\n",
    "for i in range(average_step, len(step)):\n",
    "    kl_av.append(sum(kl[i-average_step:i])/average_step)\n",
    "    ll_av.append(sum(ll[i-average_step:i])/average_step)\n",
    "    elbo_av.append(sum(elbo[i-average_step:i])/average_step)\n",
    "step = step[average_step:]\n",
    "sigma = sigma[average_step:]\n",
    "mu =mu[average_step:]\n",
    "\n",
    "plt.figure(num=None, figsize=(18, 12))\n",
    "plt.subplot(231)\n",
    "plt.plot(step, elbo_av)\n",
    "plt.subplot(232)\n",
    "plt.plot(step, ll_av)\n",
    "plt.subplot(233)\n",
    "plt.plot(step, kl_av)\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.plot(step, mu)\n",
    "plt.subplot(235)\n",
    "plt.plot(step, sigma)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "valid_dataset = GQN_Dataset(root_dir=\"data/rooms_ring_camera/\", train=False)\n",
    "x, v = valid_dataset[1]\n",
    "x = x.view((1, *x.shape))\n",
    "v = v.view((1, *v.shape))\n",
    "x, v = x.to(device), v.to(device)\n",
    "max_m=5\n",
    "x, v, x_q, v_q = partition(x, v, max_m, 5)\n",
    "batch, *_ = x.shape\n",
    "\n",
    "model = GenerativeQueryNetwork(x_dim=3, v_dim=7, r_dim=256, h_dim=128, dgf_dim=256, z_dim=64, L=8, pool=True).to(device)\n",
    "model.train()\n",
    "checkpoint = torch.load(models[-1])\n",
    "# checkpoint = torch.load(\"./checkpoints/checkpoint_model_50000.pth\") #\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "x_mu, bn1_stats, bn2_stats = model.sample(x, v, v_q)\n",
    "# x_mu, r, kl = model(x, v, x_q, v_q)\n",
    "x_mu = x_mu.detach().cpu().numpy()\n",
    "context_x = x.cpu().numpy()\n",
    "query_x = x_q.cpu().numpy()\n",
    "\n",
    "context_x = np.moveaxis(context_x, [2, 3, 4], [-1, 2, 3])\n",
    "query_x = np.moveaxis(query_x, [1, 2, 3], [-1, -3, -2])\n",
    "x_mu = np.moveaxis(x_mu, [1, 2, 3], [-1, -3, -2])\n",
    "\n",
    "n = 36\n",
    "for i in range(n):\n",
    "    full = np.concatenate(context_x[i], axis=1)\n",
    "    space = np.ones(shape=(full.shape[0], 10, 3))\n",
    "    full = np.concatenate([full, space, x_mu[i], space, query_x[i]], axis=1)\n",
    "    plt.figure(num=None, figsize=(18, 6))\n",
    "    plt.imshow(full)\n",
    "    print(i)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "delta = 0.1\n",
    "new_images = 7\n",
    "change_n = 256\n",
    "batch = 1\n",
    "\n",
    "_, _, x_dims, h, w = x.shape\n",
    "\n",
    "dgf = model.get_dgf(x, v, bn1_stats)[i]\n",
    "dgf = dgf.cpu().detach().numpy()\n",
    "\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = torch.tensor(view_q)\n",
    "\n",
    "biases = model.input_layer.bias.cpu().detach().numpy()\n",
    "\n",
    "deltas = [delta * (j - new_images//2) for j in range(new_images)]\n",
    "for neuron_i in range(change_n):\n",
    "    delta_set = []\n",
    "    images = []\n",
    "    for cur_delta in deltas:\n",
    "        new_dgf = np.copy(dgf)\n",
    "        new_dgf.astype(np.float16)\n",
    "        new_dgf[neuron_i] += cur_delta\n",
    "        delta_set.append(\"{:.5}\".format(new_dgf[neuron_i]))\n",
    "        new_dgf = np.expand_dims(new_dgf, axis=0)\n",
    "        new_dgf = torch.tensor(new_dgf)\n",
    "\n",
    "        device = torch.device(\"cpu\")\n",
    "        new_dgf, view_q = new_dgf.to(device), view_q.to(device)\n",
    "        torch.manual_seed(1)\n",
    "        x_mu = model.sample_from_dgf((batch, h, w), new_dgf, view_q, bn2_stats)\n",
    "        x_mu = x_mu.detach().cpu().numpy()\n",
    "        images.append(x_mu)\n",
    "\n",
    "    images = np.array(images)\n",
    "    images = np.reshape(images, (new_images, x_dims, h, w))\n",
    "    images = np.moveaxis(images, [1, 2, 3], [-1, -3, -2])\n",
    "    images = np.concatenate(images, axis=1)\n",
    "    print(\"i: {}, bias: {:.4}\".format(neuron_i+1, biases[neuron_i]))\n",
    "    print(\"      \",\"        \".join(delta_set))\n",
    "    plt.figure(num=None, figsize=(21,6))\n",
    "    plt.imshow(images)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgf_random = np.random.uniform(-0.05, 0.03, (1, 256))\n",
    "# dgf_manual = np.random.normal(0, 0.05, (1, 256))\n",
    "\n",
    "i=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=25\n",
    "dgf_random = model.get_dgf(x, v, bn1_stats)[i]\n",
    "dgf_random = dgf_random.cpu().detach().numpy()\n",
    "dgf_random = np.expand_dims(dgf_random, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, x_dims, h, w = x.shape\n",
    "\n",
    "# dgf_manual = np.zeros((1, 256), dtype=np.float32)\n",
    "# dgf_manual = np.random.normal(0, 0.02, (1, 256))\n",
    "# dgf_manual = np.random.uniform(-0.0, 0.05, (1, 256))\n",
    "\n",
    "dgf_manual=dgf_random.astype(np.float32)\n",
    "print(dgf_manual.dtype)\n",
    "\n",
    "\n",
    "\n",
    "dgf_manual = torch.tensor(dgf_manual)\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = torch.tensor(view_q)\n",
    "print(dgf_manual.shape)\n",
    "print(view_q.shape)\n",
    "\n",
    "dgf_manual, view_q = dgf_manual.to(device), view_q.to(device)\n",
    "torch.manual_seed(2)\n",
    "x_mu = model.sample_from_dgf((1, h, w), dgf_manual, view_q, bn2_stats)\n",
    "x_mu = x_mu.detach().cpu().numpy()[0]\n",
    "x_mu = np.moveaxis(x_mu, [0, 1, 2], [2, 0, 1])\n",
    "print(x_mu.shape)\n",
    "plt.imshow(x_mu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=9\n",
    "dgf_manual = np.copy(dgf_random)\n",
    "dgf_manual[0, 10] = 0.052\n",
    "dgf_manual[0, 51] = 0.0454\n",
    "dgf_manual[0, 120] = 0.0786\n",
    "dgf_manual[0, 142] = 0.053\n",
    "dgf_manual[0, 144] = 0.042\n",
    "dgf_manual[0, 169] = 0.0534\n",
    "dgf_manual[0, 207] = 0.0566\n",
    "dgf_manual[0, 231] = 0.04615\n",
    "dgf_manual[0, 234] = 0.085\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dgf_manual=dgf_manual.astype(np.float32)\n",
    "print(dgf_manual.dtype)\n",
    "\n",
    "\n",
    "\n",
    "dgf_manual = torch.tensor(dgf_manual)\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = torch.tensor(view_q)\n",
    "print(dgf_manual.shape)\n",
    "print(view_q.shape)\n",
    "\n",
    "dgf_manual, view_q = dgf_manual.to(device), view_q.to(device)\n",
    "torch.manual_seed(2)\n",
    "x_mu = model.sample_from_dgf((1, h, w), dgf_manual, view_q, bn2_stats)\n",
    "x_mu = x_mu.detach().cpu().numpy()[0]\n",
    "x_mu = np.moveaxis(x_mu, [0, 1, 2], [2, 0, 1])\n",
    "print(x_mu.shape)\n",
    "plt.imshow(x_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAY FLOOR\n",
    "dgf_manual = np.copy(dgf_random)\n",
    "dgf_manual[0, 8] = 0.16\n",
    "dgf_manual[0, 249] = 0.13635\n",
    "\n",
    "\n",
    "dgf_manual=dgf_manual.astype(np.float32)\n",
    "print(dgf_manual.dtype)\n",
    "\n",
    "\n",
    "\n",
    "dgf_manual = torch.tensor(dgf_manual)\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = torch.tensor(view_q)\n",
    "print(dgf_manual.shape)\n",
    "print(view_q.shape)\n",
    "\n",
    "dgf_manual, view_q = dgf_manual.to(device), view_q.to(device)\n",
    "torch.manual_seed(2)\n",
    "x_mu = model.sample_from_dgf((1, h, w), dgf_manual, view_q, bn2_stats)\n",
    "x_mu = x_mu.detach().cpu().numpy()[0]\n",
    "x_mu = np.moveaxis(x_mu, [0, 1, 2], [2, 0, 1])\n",
    "print(x_mu.shape)\n",
    "plt.imshow(x_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YELLOW FLOOR\n",
    "dgf_manual = np.copy(dgf_random)\n",
    "dgf_manual[0, 15] = 0.1472\n",
    "# dgf_manual[0, 54] = 0.1196\n",
    "# dgf_manual[0, 65] = 0.32224\n",
    "# dgf_manual[0, 136] = 0.18346\n",
    "\n",
    "\n",
    "\n",
    "dgf_manual=dgf_manual.astype(np.float32)\n",
    "print(dgf_manual.dtype)\n",
    "\n",
    "\n",
    "\n",
    "dgf_manual = torch.tensor(dgf_manual)\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = torch.tensor(view_q)\n",
    "print(dgf_manual.shape)\n",
    "print(view_q.shape)\n",
    "\n",
    "dgf_manual, view_q = dgf_manual.to(device), view_q.to(device)\n",
    "torch.manual_seed(2)\n",
    "x_mu = model.sample_from_dgf((1, h, w), dgf_manual, view_q, bn2_stats)\n",
    "x_mu = x_mu.detach().cpu().numpy()[0]\n",
    "x_mu = np.moveaxis(x_mu, [0, 1, 2], [2, 0, 1])\n",
    "print(x_mu.shape)\n",
    "plt.imshow(x_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORANGE WALLS\n",
    "dgf_manual = np.copy(dgf_random)\n",
    "# dgf_manual[0, 44] = 0.21\n",
    "# dgf_manual[0, 44] = 0.31\n",
    "dgf_manual[0, 109] = 0.12958\n",
    "# dgf_manual[0, 65] = 0.32224\n",
    "# dgf_manual[0, 136] = 0.18346\n",
    "\n",
    "\n",
    "\n",
    "dgf_manual=dgf_manual.astype(np.float32)\n",
    "print(dgf_manual.dtype)\n",
    "\n",
    "\n",
    "\n",
    "dgf_manual = torch.tensor(dgf_manual)\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = torch.tensor(view_q)\n",
    "print(dgf_manual.shape)\n",
    "print(view_q.shape)\n",
    "\n",
    "dgf_manual, view_q = dgf_manual.to(device), view_q.to(device)\n",
    "torch.manual_seed(2)\n",
    "x_mu = model.sample_from_dgf((1, h, w), dgf_manual, view_q, bn2_stats)\n",
    "x_mu = x_mu.detach().cpu().numpy()[0]\n",
    "x_mu = np.moveaxis(x_mu, [0, 1, 2], [2, 0, 1])\n",
    "print(x_mu.shape)\n",
    "plt.imshow(x_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIOLET WALLS\n",
    "dgf_manual = np.copy(dgf_random)\n",
    "dgf_manual[0, 51] = 0.1454\n",
    "dgf_manual[0, 87] = 0.20423\n",
    "\n",
    "dgf_manual=dgf_manual.astype(np.float32)\n",
    "print(dgf_manual.dtype)\n",
    "\n",
    "\n",
    "\n",
    "dgf_manual = torch.tensor(dgf_manual)\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = torch.tensor(view_q)\n",
    "print(dgf_manual.shape)\n",
    "print(view_q.shape)\n",
    "\n",
    "dgf_manual, view_q = dgf_manual.to(device), view_q.to(device)\n",
    "torch.manual_seed(2)\n",
    "x_mu = model.sample_from_dgf((1, h, w), dgf_manual, view_q, bn2_stats)\n",
    "x_mu = x_mu.detach().cpu().numpy()[0]\n",
    "x_mu = np.moveaxis(x_mu, [0, 1, 2], [2, 0, 1])\n",
    "print(x_mu.shape)\n",
    "plt.imshow(x_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORANGE WALLS\n",
    "dgf_manual = np.copy(dgf_random)\n",
    "dgf_manual[0, 205] = 0.15035\n",
    "# dgf_manual[0, 224] = 0.094652\n",
    "# dgf_manual[0, 44] = 0.31\n",
    "# dgf_manual[0, 109] = 0.12958\n",
    "# dgf_manual[0, 65] = 0.32224\n",
    "# dgf_manual[0, 136] = 0.18346\n",
    "\n",
    "\n",
    "\n",
    "dgf_manual=dgf_manual.astype(np.float32)\n",
    "print(dgf_manual.dtype)\n",
    "\n",
    "\n",
    "\n",
    "dgf_manual = torch.tensor(dgf_manual)\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = torch.tensor(view_q)\n",
    "print(dgf_manual.shape)\n",
    "print(view_q.shape)\n",
    "\n",
    "dgf_manual, view_q = dgf_manual.to(device), view_q.to(device)\n",
    "torch.manual_seed(2)\n",
    "x_mu = model.sample_from_dgf((1, h, w), dgf_manual, view_q, bn2_stats)\n",
    "x_mu = x_mu.detach().cpu().numpy()[0]\n",
    "x_mu = np.moveaxis(x_mu, [0, 1, 2], [2, 0, 1])\n",
    "print(x_mu.shape)\n",
    "plt.imshow(x_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=14\n",
    "delta = 0.1\n",
    "new_images = 7\n",
    "change_n = 256\n",
    "batch = 1\n",
    "\n",
    "_, _, x_dims, h, w = x.shape\n",
    "\n",
    "dgf = model.get_dgf(x, v, bn1_stats)[i]\n",
    "dgf = dgf.cpu().detach().numpy()\n",
    "\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = torch.tensor(view_q)\n",
    "\n",
    "biases = model.input_layer.bias.cpu().detach().numpy()\n",
    "\n",
    "deltas = [delta * (j - new_images//2) for j in range(new_images)]\n",
    "for neuron_i in range(change_n):\n",
    "    delta_set = []\n",
    "    images = []\n",
    "    for cur_delta in deltas:\n",
    "        new_dgf = np.copy(dgf)\n",
    "        new_dgf.astype(np.float16)\n",
    "        new_dgf[neuron_i] += cur_delta\n",
    "        delta_set.append(\"{:.5}\".format(new_dgf[neuron_i]))\n",
    "        new_dgf = np.expand_dims(new_dgf, axis=0)\n",
    "        new_dgf = torch.tensor(new_dgf)\n",
    "\n",
    "        device = torch.device(\"cpu\")\n",
    "        new_dgf, view_q = new_dgf.to(device), view_q.to(device)\n",
    "        torch.manual_seed(1)\n",
    "        x_mu = model.sample_from_dgf((batch, h, w), new_dgf, view_q, bn2_stats)\n",
    "        x_mu = x_mu.detach().cpu().numpy()\n",
    "        images.append(x_mu)\n",
    "\n",
    "    images = np.array(images)\n",
    "    images = np.reshape(images, (new_images, x_dims, h, w))\n",
    "    images = np.moveaxis(images, [1, 2, 3], [-1, -3, -2])\n",
    "    images = np.concatenate(images, axis=1)\n",
    "    print(\"i: {}, bias: {:.4}\".format(neuron_i+1, biases[neuron_i]))\n",
    "    print(\"      \",\"        \".join(delta_set))\n",
    "    plt.figure(num=None, figsize=(21,6))\n",
    "    plt.imshow(images)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "### MORE EFFECTIVE CODE, BUT WITHOUT SEED!!!!!!!!!\n",
    "###\n",
    "\n",
    "delta = 0.1\n",
    "new_images = 7\n",
    "change_n = 256\n",
    "batch = new_images*change_n\n",
    "\n",
    "_, _, x_dims, h, w = x.shape\n",
    "\n",
    "dgf = model.get_dgf(x, v, bn1_stats)[i]\n",
    "dgf = dgf.cpu().detach().numpy()\n",
    "dgf_dims = dgf.shape[0]\n",
    "dgf = np.reshape(dgf, (1, dgf.shape[0]))\n",
    "new_dgf = np.repeat(dgf, batch, axis=0)\n",
    "\n",
    "deltas = np.zeros((batch, dgf_dims), dtype=np.float16)\n",
    "delta_row = [delta * (j - new_images//2) for j in range(new_images)]\n",
    "for j in range(0, change_n):\n",
    "    deltas[j*new_images:j*new_images+new_images, j] = delta_row\n",
    "\n",
    "new_dgf = new_dgf + deltas\n",
    "\n",
    "view_q = v_q[i].cpu().detach().numpy()\n",
    "view_q = np.reshape(view_q, (1,  view_q.shape[0]))\n",
    "view_q = np.repeat(view_q, batch, axis=0)\n",
    "\n",
    "view_q = torch.tensor(view_q)\n",
    "new_dgf = torch.tensor(new_dgf)\n",
    "print(new_dgf.shape)\n",
    "print(view_q.shape)\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "new_dgf, view_q = new_dgf.to(device), view_q.to(device)\n",
    "x_mu = model.sample_from_dgf((batch, h, w), new_dgf, view_q, bn2_stats)\n",
    "x_mu = x_mu.detach().cpu().numpy()\n",
    "x_mu = np.moveaxis(x_mu, [1, 2, 3], [-1, -3, -2])\n",
    "new_dgf_np = new_dgf.detach().cpu().numpy()\n",
    "\n",
    "for j in range(change_n):\n",
    "    change_set = x_mu[j*new_images:j*new_images+new_images]\n",
    "    delta_set = new_dgf_np[j*new_images:j*new_images+new_images, j]\n",
    "    images = np.concatenate(change_set, axis=1)\n",
    "    delta_set = delta_set.astype(np.float16)\n",
    "    print(\"      \", \"         \".join(map(str, delta_set)))\n",
    "    plt.figure(num=None, figsize=(21,6))\n",
    "    plt.imshow(images)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
